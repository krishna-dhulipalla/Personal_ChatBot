# ğŸ§  Krishna's Personal AI Chatbot

A memory-grounded, retrieval-augmented AI assistant built with LangChain, FAISS, BM25, and Llama3 â€” personalized to Krishna Vamsi Dhulipallaâ€™s career, projects, and technical profile.

> âš¡ï¸ Ask me anything about Krishna â€” skills, experience, goals, or even what tools he used at Virginia Tech.

---

## ğŸ“Œ Features

- âœ… **Hybrid Retrieval**: Combines dense vector search (FAISS) + keyword search (BM25) for precise, high-recall chunk selection
- ğŸ¤– **LLM-Powered Pipelines**: Uses OpenAI GPT-4o and NVIDIA NIMs (e.g. LLaMA-3, Mixtral) for rewriting, validation, and final answer generation
- ğŸ§  **Memory Module**: Stores user preferences, recent topics, and inferred tone using a structured `KnowledgeBase` schema
- ğŸ› ï¸ **Custom Architecture**:
  - Query â†’ Rewriting â†’ Hybrid Retriever â†’ Scope Validator â†’ LLM Answer
  - Fallback humor model (Mixtral) for out-of-scope queries
- ğŸ§© **Document Grounding**: Powered by Krishnaâ€™s actual markdown files like `profile.md`, `goals.md`, and `chatbot_architecture.md`
- ğŸ“Š **Enriched Vector Store**: Chunks include LLM-generated summaries and synthetic queries for better search performance
- ğŸ›ï¸ **Gradio Frontend**: Responsive, markdown-formatted interface for natural, real-time interaction

---

## ğŸ—ï¸ Architecture

```text
User Query
   â†“
[LLM1] â†’ Rephrase into 3 diverse subqueries
   â†“
Hybrid Retrieval (BM25 + FAISS)
   â†“
[LLM2] â†’ Classify: In-scope or Out-of-scope
   â†“
   â”œâ”€ In-scope â†’ Top-k Chunks â†’ GPT-4o
   â””â”€ Out-of-scope â†’ Mixtral (funny fallback)
   â†“
Final Answer + Async Memory Update
```

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ app.py                      # Main Gradio app and pipeline logic
â”œâ”€â”€ Vector_storing.py          # Chunking, LLM-based enrichment, and FAISS store creation
â”œâ”€â”€ requirements.txt           # Python package dependencies
â”œâ”€â”€ faiss_store/               # Saved FAISS vector index
â”œâ”€â”€ all_chunks.json            # JSON of enriched document chunks
â”œâ”€â”€ personal_data/             # Source markdown files (right now excluded)
â”œâ”€â”€ README.md
```

---

## ğŸ§  Knowledge Sources

All answers are grounded in curated markdown files:

| File Name                 | Description                                    |
| ------------------------- | ---------------------------------------------- |
| `profile.md`              | Krishnaâ€™s full technical profile and education |
| `goals.md`                | Short- and long-term personal goals            |
| `chatbot_architecture.md` | System-level breakdown of this AI assistant    |
| `personal_interests.md`   | Hobbies, cultural identity, food preferences   |
| `conversations.md`        | Sample queries and expected response tone      |

---

## ğŸ§ª How It Works

1. **User input** is rewritten into subqueries (LLM1)
2. **Retriever** fetches relevant chunks using BM25 and FAISS
3. **Classifier LLM** decides if results are relevant to Krishna
4. **GPT-4o** generates final answer using top-k chunks
5. **Memory is updated** asynchronously with every turn

---

## ğŸ’¬ Example Queries

- What programming languages does Krishna know?
- Tell me about Krishnaâ€™s chatbot architecture
- Can this chatbot explain Krishna's work at Virginia Tech?
- What tools has Krishna used for data engineering?

---

## ğŸš€ Setup & Usage

```bash
# 1. Clone the repo
git clone https://github.com/krishna-creator/krishna-personal-chatbot.git
cd krishna-personal-chatbot

# 2. Install dependencies
pip install -r requirements.txt

# 3. Set your API keys (OpenAI, NVIDIA)
export OPENAI_API_KEY=...
export NVIDIA_API_KEY=...

# 4. Launch the chatbot
python app.py
```

---

## ğŸ”® Model Stack

| Purpose            | Model Name               | Provider |
| ------------------ | ------------------------ | -------- |
| Query Rewriting    | `phi-3-mini-4k-instruct` | NVIDIA   |
| Scope Classifier   | `llama-3-70b-instruct`   | NVIDIA   |
| Answer Generator   | `gpt-4o`                 | OpenAI   |
| Fallback Humor LLM | `mixtral-8x22b-instruct` | NVIDIA   |

---

## ğŸ“Œ Acknowledgments

- Built as part of Krishna's exploration into **LLM orchestration and agentic RAG**
- Inspired by LangChain, SentenceTransformers, and NVIDIA RAG Agents Course

---

## ğŸ“œ License

MIT License Â© Krishna Vamsi Dhulipalla
